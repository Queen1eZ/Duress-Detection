{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 20593,
     "status": "ok",
     "timestamp": 1745696659265,
     "user": {
      "displayName": "luki",
      "userId": "03756246528752990463"
     },
     "user_tz": 420
    },
    "id": "w8zVYqjySqCq",
    "outputId": "e651a1a3-2ab2-4c39-eaec-5335a9feafbf"
   },
   "outputs": [],
   "source": [
    "pip install opensmile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HHANrkMFgGYB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import opensmile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YhnK0mCvSnCd"
   },
   "outputs": [],
   "source": [
    "# initialize OpenSMILE\n",
    "smile_lld = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.ComParE_2016,\n",
    "    feature_level=opensmile.FeatureLevel.LowLevelDescriptors\n",
    ")\n",
    "smile_func = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals\n",
    ")\n",
    "\n",
    "def compute_lld_stats(X_lld):\n",
    "    \"\"\"Compute global statistical features (mean, std, max, min) for LLDs\"\"\"\n",
    "    lld_values = X_lld.values\n",
    "    stats = np.hstack([\n",
    "        np.mean(lld_values, axis=0).reshape(1, -1),\n",
    "        np.std(lld_values, axis=0).reshape(1, -1),\n",
    "        np.max(lld_values, axis=0).reshape(1, -1),\n",
    "        np.min(lld_values, axis=0).reshape(1, -1)\n",
    "    ])\n",
    "    return stats\n",
    "\n",
    "def process_audio_file(filepath):\n",
    "    \"\"\"Extract and combine acoustic features from a single audio file\"\"\"\n",
    "    try:\n",
    "        features = {}\n",
    "\n",
    "        # 1. Extract Low-Level Descriptors (LLDs)\n",
    "        X_lld = smile_lld.process_file(filepath)\n",
    "        lld_stats = compute_lld_stats(X_lld)\n",
    "\n",
    "        # 2. Extract Functionals (eGeMAPS)\n",
    "        X_func = smile_func.process_file(filepath)\n",
    "\n",
    "        # 3. Combine all features\n",
    "        acoustic_features = np.hstack([lld_stats, X_func.values])\n",
    "\n",
    "        # 4. Generate feature names\n",
    "        lld_feature_names = [f\"{col}_{stat}\" for col in X_lld.columns for stat in ['mean', 'std', 'max', 'min']]\n",
    "        func_feature_names = X_func.columns.tolist()\n",
    "        all_feature_names = lld_feature_names + func_feature_names\n",
    "\n",
    "        # 5. Map features to names\n",
    "        for name, value in zip(all_feature_names, acoustic_features[0]):\n",
    "            features[name] = value\n",
    "\n",
    "        return features\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing audio: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vMU3tMZhSr8b"
   },
   "outputs": [],
   "source": [
    "def compute_lld_stats(X_lld):\n",
    "    \"\"\"Compute global statistical features (mean, std, max, min) for LLDs\"\"\"\n",
    "    lld_values = X_lld.values\n",
    "    stats = np.hstack([\n",
    "        np.mean(lld_values, axis=0).reshape(1, -1),\n",
    "        np.std(lld_values, axis=0).reshape(1, -1),\n",
    "        np.max(lld_values, axis=0).reshape(1, -1),\n",
    "        np.min(lld_values, axis=0).reshape(1, -1)\n",
    "    ])\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KwbnN_HySr6b"
   },
   "outputs": [],
   "source": [
    "def process_audio_file(filepath):\n",
    "    \"\"\"Extract and combine acoustic features from a single audio file\"\"\"\n",
    "    try:\n",
    "        features = {}\n",
    "\n",
    "        # 1. Extract Low-Level Descriptors (LLDs)\n",
    "        X_lld = smile_lld.process_file(filepath)\n",
    "        lld_stats = compute_lld_stats(X_lld)\n",
    "\n",
    "        # 2. Extract Functionals (eGeMAPS)\n",
    "        X_func = smile_func.process_file(filepath)\n",
    "\n",
    "        # 3. Combine all features\n",
    "        acoustic_features = np.hstack([lld_stats, X_func.values])\n",
    "\n",
    "        # 4. Generate feature names\n",
    "        lld_feature_names = [f\"{col}_{stat}\" for col in X_lld.columns for stat in ['mean', 'std', 'max', 'min']]\n",
    "        func_feature_names = X_func.columns.tolist()\n",
    "        all_feature_names = lld_feature_names + func_feature_names\n",
    "\n",
    "        # 5. Map features to names\n",
    "        for name, value in zip(all_feature_names, acoustic_features[0]):\n",
    "            features[name] = value\n",
    "\n",
    "        return features\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing audio: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mfFvsV6Gfjd9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TZ2nWwKF5bVD"
   },
   "outputs": [],
   "source": [
    "# ========= Configuration =========\n",
    "SCALER_PATH = \"/content/drive/My Drive/BECU Capstone_Duress/Model/scaler.pkl\"\n",
    "FEATURES_PATH = '/content/drive/My Drive/BECU Capstone_Duress/Model/selected_idx.pkl'\n",
    "LSTM_MODEL_PATH = \"/content/drive/My Drive/BECU Capstone_Duress/Model/lstm_model.keras\"\n",
    "RF_MODEL_PATH = \"/content/drive/My Drive/BECU Capstone_Duress/Model/rf_model.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Weez9kBA-b2F"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Data to test(path needed to be change)\n",
    "input_files = glob.glob('/content/drive/BECU Capstone_Duress/Data/911call/*.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 84554,
     "status": "ok",
     "timestamp": 1745697035019,
     "user": {
      "displayName": "luki",
      "userId": "03756246528752990463"
     },
     "user_tz": 420
    },
    "id": "lt_NjSZfdaWM",
    "outputId": "d659cc8c-48a5-445f-dfc1-db5fe1a56d6e"
   },
   "outputs": [],
   "source": [
    "all_features = []\n",
    "file_names = []\n",
    "\n",
    "for input_file in input_files:\n",
    "    print(f\"Processing: {input_file}\")\n",
    "    features = process_audio_file(input_file)\n",
    "    if features:\n",
    "        all_features.append(features)\n",
    "        file_names.append(input_file.split('/')[-1])\n",
    "\n",
    "# Combine and save\n",
    "if all_features:\n",
    "    df = pd.DataFrame(all_features)\n",
    "else:\n",
    "    print(\"No features extracted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1745697055587,
     "user": {
      "displayName": "luki",
      "userId": "03756246528752990463"
     },
     "user_tz": 420
    },
    "id": "NivsCHizYTsz",
    "outputId": "589868ea-1097-487e-d4b7-3686bad01a4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5] Loading data...\n"
     ]
    }
   ],
   "source": [
    "# ========= Data Loading =========\n",
    "print(\"[1/5] Loading data...\")\n",
    "new_data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4862,
     "status": "ok",
     "timestamp": 1745699089589,
     "user": {
      "displayName": "luki",
      "userId": "03756246528752990463"
     },
     "user_tz": 420
    },
    "id": "oMHbJvuPOwl-",
    "outputId": "e6e31b65-21c8-4cf4-f97d-b8f5271f0430"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/5] Loading preprocessing objects...\n",
      "[3/5] Preprocessing data...\n",
      "[4/5] Loading models...\n",
      "[5/5] Making predictions...\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step\n",
      "\n",
      "Prediction Results:\n",
      "          Filename  Prediction_Code Prediction_Label       pro\n",
      "0   call_111_0.wav                0        no duress  0.589801\n",
      "1   call_107_0.wav                0        no duress  0.357011\n",
      "2   call_108_0.wav                0        no duress  0.545051\n",
      "3   call_109_0.wav                0        no duress  0.310220\n",
      "4   call_115_0.wav                0        no duress  0.606012\n",
      "..             ...              ...              ...       ...\n",
      "95   call_12_0.wav                0        no duress  0.545815\n",
      "96    call_2_0.wav                0        no duress  0.674830\n",
      "97   call_10_0.wav                0        no duress  0.586833\n",
      "98    call_9_0.wav                0        no duress  0.676746\n",
      "99   call_13_0.wav                0        no duress  0.441214\n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# ========= Preprocessing =========\n",
    "print(\"[2/5] Loading preprocessing objects...\")\n",
    "scaler = joblib.load(SCALER_PATH)\n",
    "selected_idx = joblib.load(FEATURES_PATH)\n",
    "\n",
    "print(\"[3/5] Preprocessing data...\")\n",
    "data_scaled = scaler.transform(new_data)\n",
    "data_sel = data_scaled[:, selected_idx]\n",
    "\n",
    "# ========= Model Loading =========\n",
    "print(\"[4/5] Loading models...\")\n",
    "keras.config.enable_unsafe_deserialization()\n",
    "best_lstm_model = tf.keras.models.load_model(\n",
    "    LSTM_MODEL_PATH,\n",
    "    custom_objects={'tf': tf}\n",
    ")\n",
    "best_rf_model = joblib.load(RF_MODEL_PATH)\n",
    "\n",
    "# ========= Prediction =========\n",
    "print(\"[5/5] Making predictions...\")\n",
    "# Prepare LSTM input\n",
    "new_data_lstm = data_sel.reshape((-1, 1, data_sel.shape[1]))\n",
    "\n",
    "# Get model probabilities\n",
    "lstm_proba = best_lstm_model.predict(new_data_lstm).flatten()\n",
    "rf_proba = best_rf_model.predict_proba(data_sel)[:, 1]\n",
    "\n",
    "# Ensemble predictions\n",
    "final_proba = (lstm_proba + rf_proba) / 2  # Simple average ensemble\n",
    "final_pred = (final_proba > 0.7).astype(int)  # Threshold at 0.7 (reduce false positive)\n",
    "\n",
    "# ========= Results =========\n",
    "print(\"\\nPrediction Results:\")\n",
    "result_df = pd.DataFrame({\n",
    "    \"Filename\": file_names,\n",
    "    \"Prediction_Code\": final_pred,\n",
    "    \"Prediction_Label\": pd.Series(final_pred).map({1: \"duress\", 0: \"no duress\"}),\"pro\": final_proba\n",
    "})\n",
    "\n",
    "print(result_df)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
