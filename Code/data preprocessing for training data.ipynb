{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 8315,
     "status": "ok",
     "timestamp": 1744997914510,
     "user": {
      "displayName": "luki",
      "userId": "03756246528752990463"
     },
     "user_tz": 420
    },
    "id": "w0fSvnK9gGYA",
    "outputId": "ed5c3a8c-d245-437e-929c-8d5a00197ce9"
   },
   "outputs": [],
   "source": [
    "pip install opensmile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HHANrkMFgGYB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import opensmile\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cgDdNtLEqP7C"
   },
   "outputs": [],
   "source": [
    "# initialize OpenSMILE\n",
    "smile_lld = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.ComParE_2016,\n",
    "    feature_level=opensmile.FeatureLevel.LowLevelDescriptors\n",
    ")\n",
    "smile_func = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C9uYrYBCqSmf"
   },
   "outputs": [],
   "source": [
    "output_path = '/content/drive/My Drive/BECU Capstone_Duress/Data_preprocessed/CREMAD DATA.csv'# Preprocessed Data\n",
    "input_dir = '/content/drive/My Drive/BECU Capstone_Duress/Data/CREMAD DATA'# Original Data\n",
    "# Create a DataFrame for storing the results\n",
    "all_features = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u4AfLv-SqdMA"
   },
   "outputs": [],
   "source": [
    "# Emotion coding mapping dictionary\n",
    "\n",
    "EMOTION_MAP = {\n",
    "    'ANG': 'anger',\n",
    "    'DIS': 'disgust',\n",
    "    'FEA': 'fear',\n",
    "    'HAP': 'happy',\n",
    "    'NEU': 'neutral',\n",
    "    'SAD': 'sad'\n",
    "}\n",
    "\n",
    "DURESS_CODES = {'ANG', 'SAD', 'FEA'}  # sad,angry,fearful -> duress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 752,
     "status": "ok",
     "timestamp": 1744928306676,
     "user": {
      "displayName": "luki",
      "userId": "03756246528752990463"
     },
     "user_tz": 420
    },
    "id": "nKf9UqyRsxwP",
    "outputId": "06ada875-c3f0-40ed-e4e9-5f5f3c51b37d"
   },
   "outputs": [],
   "source": [
    "#This should be modified according to the actual situation, if there is a feature file\n",
    "\n",
    "metadata_path = '/content/drive/My Drive/Colab Notebooks/VideoDemographics.csv'\n",
    "try:\n",
    "    actor_metadata = pd.read_csv(metadata_path)\n",
    "    # Make sure the ActorID column is of string type in order to match the ID in the file name\n",
    "    actor_metadata['ActorID'] = actor_metadata['ActorID'].astype(str)\n",
    "    # Create a dictionary indexed by ActorID for quick lookup\n",
    "    actor_dict = actor_metadata.set_index('ActorID').to_dict('index')\n",
    "    print(f\"Successfully loaded {len(actor_metadata)} actors' metadata\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load the metadata file: {str(e)}\")\n",
    "    actor_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fI4X2TJWtGd5"
   },
   "outputs": [],
   "source": [
    "# CREMAD Metadata parsing function\n",
    "# 1001_DFA_ANG_XX.wav\n",
    "def parse_filename(filename):\n",
    "\n",
    "    try:\n",
    "        base_name = os.path.splitext(filename)[0]\n",
    "        parts = base_name.split('_')\n",
    "        return {\n",
    "            'emotion_code': parts[2],\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing {filename}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_AXiQBMH30zY"
   },
   "outputs": [],
   "source": [
    "def compute_lld_stats(X_lld):\n",
    "    \"\"\"Compute global statistical features (mean, std, max, min) for LLDs\"\"\"\n",
    "    lld_values = X_lld.values\n",
    "    stats = np.hstack([\n",
    "        np.mean(lld_values, axis=0).reshape(1, -1),\n",
    "        np.std(lld_values, axis=0).reshape(1, -1),\n",
    "        np.max(lld_values, axis=0).reshape(1, -1),\n",
    "        np.min(lld_values, axis=0).reshape(1, -1)\n",
    "    ])\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1624997,
     "status": "ok",
     "timestamp": 1744932160866,
     "user": {
      "displayName": "luki",
      "userId": "03756246528752990463"
     },
     "user_tz": 420
    },
    "id": "Yrh63-kr9vCj",
    "outputId": "03e4e4a9-5d3d-4248-e2cb-ba0ad66bafb9"
   },
   "outputs": [],
   "source": [
    "def process_audio_file(filepath, filename):\n",
    "    \"\"\"Extract and combine acoustic features from a single audio file\"\"\"\n",
    "    try:\n",
    "        # Parse the file name to obtain the metadata\n",
    "        meta = parse_filename(filename)\n",
    "        if not meta:\n",
    "            return None\n",
    "\n",
    "        features = {}  \n",
    "\n",
    "        # 1. Extract Low-Level Descriptors (LLDs)\n",
    "        X_lld = smile_lld.process_file(filepath)  # Shape: (num_frames, num_features)\n",
    "\n",
    "        # 2. Compute LLD statistics\n",
    "        lld_stats = compute_lld_stats(X_lld)  # Shape: (1, 4*num_features)\n",
    "\n",
    "        # 3. Extract Functionals (eGeMAPS)\n",
    "        X_func = smile_func.process_file(filepath)  # Shape: (1, num_functionals)\n",
    "\n",
    "        # 4. Combine all acoustic features\n",
    "        acoustic_features = np.hstack([lld_stats, X_func.values])\n",
    "\n",
    "        # 5. Create feature names\n",
    "        lld_feature_names = [f\"{col}_{stat}\" for col in X_lld.columns\n",
    "                           for stat in ['mean', 'std', 'max', 'min']]\n",
    "        func_feature_names = X_func.columns.tolist()\n",
    "        all_feature_names = lld_feature_names + func_feature_names\n",
    "\n",
    "        # 6. Convert to dictionary\n",
    "        for name, value in zip(all_feature_names, acoustic_features[0]):\n",
    "            features[name] = value\n",
    "\n",
    "\n",
    "\n",
    "        # Add metadata to the features as Labels\n",
    "        features.update({\n",
    "            'duress_label': 1 if meta['emotion_code'] in DURESS_CODES else 0\n",
    "        })\n",
    "\n",
    "        return features\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error handling {filename}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def process_directory(directory):\n",
    "    \"\"\"Process all audio files in the directory\"\"\"\n",
    "    data_list = [] \n",
    "\n",
    "    # Obtain all.wav files in the directory\n",
    "    audio_files = [f for f in os.listdir(directory) if f.endswith('.wav')]\n",
    "\n",
    "    for filename in tqdm(audio_files, desc=f\"Processing directory: {directory}\"):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        features = process_audio_file(filepath, filename)\n",
    "\n",
    "        if features:\n",
    "            data_list.append(features)\n",
    "\n",
    "    return pd.DataFrame(data_list) if data_list else pd.DataFrame()\n",
    "\n",
    "# Main processing flow\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Suppose the input directory directly contains all audio files\n",
    "input_dir = '/content/drive/My Drive/BECU Capstone_Duress/Data/CREMAD DATA'\n",
    "\n",
    "# If there is a multi-level directory structure, this part needs to be modified\n",
    "try:\n",
    "    print(f\"Processing directory: {input_dir}\")\n",
    "    dir_data = process_directory(input_dir)\n",
    "    if not dir_data.empty:\n",
    "        all_data = pd.concat([all_data, dir_data], ignore_index=True)\n",
    "except Exception as e:\n",
    "    print(f\"Error processing directory {input_dir}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8911,
     "status": "ok",
     "timestamp": 1744932300683,
     "user": {
      "displayName": "luki",
      "userId": "03756246528752990463"
     },
     "user_tz": 420
    },
    "id": "_TPT54r5uG7Z",
    "outputId": "d6e19b71-39be-4ae7-f6f8-07ff7ae7f727"
   },
   "outputs": [],
   "source": [
    "# Print processing summary\n",
    "if not all_data.empty:\n",
    "    # Define column order for better readability\n",
    "    column_order = [\n",
    "        'duress_label'\n",
    "    ]\n",
    "\n",
    "    # Include all remaining feature columns (from OpenSMILE)\n",
    "    remaining_columns = [col for col in all_data.columns if col not in column_order]\n",
    "\n",
    "    # Final column ordering\n",
    "    final_columns = column_order + sorted(remaining_columns)\n",
    "    all_data = all_data[final_columns]\n",
    "\n",
    "    # Print dataset statistics\n",
    "    print(\"\\n=== Dataset Summary ===\")\n",
    "    print(f\"Total samples: {len(all_data)}\")\n",
    "    print(f\"Features per sample: {len(remaining_columns)} acoustic features\")\n",
    "\n",
    "    # Label distribution analysis\n",
    "    print(\"\\n=== Label Distribution ===\")\n",
    "    print(\"\\nDuress label (1=duress, 0=neutral/positive):\")\n",
    "    print(all_data['duress_label'].value_counts())\n",
    "\n",
    "\n",
    "    # Save to CSV with verification\n",
    "    try:\n",
    "        all_data.to_csv(output_path, index=False)\n",
    "\n",
    "        # Verify save operation\n",
    "        if os.path.exists(output_path):\n",
    "            saved_data = pd.read_csv(output_path)\n",
    "            print(f\"\\nSUCCESS: Saved {len(saved_data)} samples to:\")\n",
    "            print(output_path)\n",
    "            print(f\"File size: {os.path.getsize(output_path)/1024/1024:.2f} MB\")\n",
    "        else:\n",
    "            print(\"\\nWARNING: File created but cannot be verified\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nERROR saving file: {str(e)}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nPROCESSING FAILED: No valid data was processed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w3YL0qrIgGYG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
